{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Анализ-данных\" data-toc-modified-id=\"Анализ-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Анализ данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Общий-выводы\" data-toc-modified-id=\"Общий-выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Общий выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим наш датасет и посмотрим на него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в датасете равно 159571 шт\n"
     ]
    }
   ],
   "source": [
    "print('Количество строк в датасете равно {} шт'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на соотношения классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Количество</th>\n",
       "      <th>% от количества</th>\n",
       "      <th>Тип комментария</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143346</td>\n",
       "      <td>89.83</td>\n",
       "      <td>Позитивные</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16225</td>\n",
       "      <td>10.17</td>\n",
       "      <td>Негативные</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Количество  % от количества Тип комментария\n",
       "0      143346            89.83      Позитивные\n",
       "1       16225            10.17      Негативные"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Количество':df['toxic'].value_counts(), \n",
    "              '% от количества': (df['toxic'].value_counts()/len(df)*100).round(2),\n",
    "             'Тип комментария': ['Позитивные', 'Негативные']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на количество пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов в данных равно 0\n"
     ]
    }
   ],
   "source": [
    "print('Количество дубликатов в данных равно {}'.format(df.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы загрузили и посмотрели на данные. В нашем датасете 159571 строк содержащих комментарии пользователей, из них:\n",
    "- 143346 шт являются 'Позитивными', это почти 90% данных\n",
    "- 16225 шт являются 'Негативными', это около 10% данных  \n",
    "\n",
    "В данных нет пропусков и дубликатов. Можно приступать к обработке данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью регулярных выражений очистим тест от лишней информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_cleared'] = df['text'].apply(lambda x: re.sub('[^A-Za-z]', ' ', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_cleared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                        text_cleared  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww  he matches this background colour i m s...  \n",
       "2  hey man  i m really not trying to edit war  it...  \n",
       "3    more i can t make any real suggestions on im...  \n",
       "4  you  sir  are my hero  any chance you remember...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим список стоп-слов из английского языка. Далее отфильтруем наши сообщения, возьмем слова которые не находятся в списке стоп слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/maxim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_split'] = df['text_cleared'].map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['not_stopwords'] = df['text_split'].map(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_cleared</th>\n",
       "      <th>text_split</th>\n",
       "      <th>not_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>[d, aww, he, matches, this, background, colour...</td>\n",
       "      <td>[aww, matches, background, colour, seemingly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>[hey, man, i, m, really, not, trying, to, edit...</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "      <td>[more, i, can, t, make, any, real, suggestions...</td>\n",
       "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                        text_cleared  \\\n",
       "0  explanation why the edits made under my userna...   \n",
       "1  d aww  he matches this background colour i m s...   \n",
       "2  hey man  i m really not trying to edit war  it...   \n",
       "3    more i can t make any real suggestions on im...   \n",
       "4  you  sir  are my hero  any chance you remember...   \n",
       "\n",
       "                                          text_split  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [d, aww, he, matches, this, background, colour...   \n",
       "2  [hey, man, i, m, really, not, trying, to, edit...   \n",
       "3  [more, i, can, t, make, any, real, suggestions...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                       not_stopwords  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [aww, matches, background, colour, seemingly, ...  \n",
       "2  [hey, man, really, trying, edit, war, guy, con...  \n",
       "3  [make, real, suggestions, improvement, wondere...  \n",
       "4                [sir, hero, chance, remember, page]  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим леммы полученных предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/maxim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/maxim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "        \n",
    "    return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmas'] = df['not_stopwords'].apply(lambda x: [lemmatize(\" \".join(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество элементов обучающей выборки: 80%\n",
      "Количество элементов тестовой выборки: 20%\n"
     ]
    }
   ],
   "source": [
    "X = df['lemmas']\n",
    "y = df['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print('Количество элементов обучающей выборки: {:.0f}%'.format(X_train.shape[0]/df.shape[0] * 100))\n",
    "print('Количество элементов тестовой выборки: {:.0f}%'.format(X_test.shape[0]/df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим tf-idf для текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('U')\n",
    "X_test = X_test.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе мы получили леммы в предложениях. Далее разбили данные на обучающую и тестовую выборку, теперь можно приступать к обучению моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим следующие модели:\n",
    "\n",
    "- Логистическая регрессия\n",
    "- Дерево решений\n",
    "- Случайый лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(model_name, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    pipe_lr = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                        ('clf', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=123))])\n",
    "    \n",
    "    grid_params_lr = [{'clf__fit_intercept': [True, False],\n",
    "                       'clf__C': [0.1, 1, 10, 100],\n",
    "                       'clf__solver': ['liblinear', 'lbfgs']}]\n",
    "    \n",
    "    lr_model = GridSearchCV(estimator=pipe_lr,\n",
    "                      param_grid=grid_params_lr,\n",
    "                      scoring='f1',\n",
    "                      cv=3,\n",
    "                      n_jobs=-1)\n",
    "    \n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    return {\n",
    "        'Название модели': model_name,\n",
    "        'Параметры модели': lr_model.best_params_,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = log_reg('LogisticRegression', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(log_reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Название модели</th>\n",
       "      <th>Параметры модели</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'clf__C': 10, 'clf__fit_intercept': True, 'cl...</td>\n",
       "      <td>0.76207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Название модели                                   Параметры модели  \\\n",
       "0  LogisticRegression  {'clf__C': 10, 'clf__fit_intercept': True, 'cl...   \n",
       "\n",
       "   f1_score  \n",
       "0   0.76207  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_classifier(model_name, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    pipe_dt = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                        ('clf', DecisionTreeClassifier(class_weight='balanced', random_state=123))])\n",
    "    \n",
    "    grid_params_dt = [{'clf__max_depth':[5, 10, 15],\n",
    "                       'clf__min_samples_split':[5, 7, 9],\n",
    "                       'clf__min_samples_leaf':[3, 5, 7],\n",
    "                       'clf__criterion': ['gini', 'entropy']}]\n",
    "    \n",
    "    dt_model = GridSearchCV(estimator=pipe_dt,\n",
    "                      param_grid=grid_params_dt,\n",
    "                      scoring='f1',\n",
    "                      cv=3,\n",
    "                      n_jobs=-1)\n",
    "    \n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = dt_model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    return {\n",
    "        'Название модели': model_name,\n",
    "        'Параметры модели': dt_model.best_params_,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier_model = dt_classifier('DecisionTreeClassifier', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(dt_classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Название модели</th>\n",
       "      <th>Параметры модели</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'clf__C': 10, 'clf__fit_intercept': True, 'cl...</td>\n",
       "      <td>0.762070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_depth'...</td>\n",
       "      <td>0.612802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Название модели                                   Параметры модели  \\\n",
       "0      LogisticRegression  {'clf__C': 10, 'clf__fit_intercept': True, 'cl...   \n",
       "1  DecisionTreeClassifier  {'clf__criterion': 'entropy', 'clf__max_depth'...   \n",
       "\n",
       "   f1_score  \n",
       "0  0.762070  \n",
       "1  0.612802  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classifier(model_name, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    pipe_rf = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                        ('clf', RandomForestClassifier(class_weight='balanced', random_state=123))])\n",
    "    \n",
    "    grid_params_rf = [{'clf__max_depth':[10, 15, 20, 25, 30],\n",
    "                       'clf__n_estimators':[30, 40, 50],\n",
    "                       'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "                       'clf__criterion': ['gini', 'entropy']}]\n",
    "\n",
    "    rf_model = GridSearchCV(estimator=pipe_rf,\n",
    "                      param_grid=grid_params_rf,\n",
    "                      scoring='f1',\n",
    "                      cv=3,\n",
    "                      n_jobs=-1)\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = rf_model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    return {\n",
    "        'Название модели': model_name,\n",
    "        'Параметры модели': rf_model.best_params_,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_model = rf_classifier('RandomForestClassifier', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(rf_classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Название модели</th>\n",
       "      <th>Параметры модели</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'clf__C': 10, 'clf__fit_intercept': True, 'cl...</td>\n",
       "      <td>0.762070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'clf__criterion': 'entropy', 'clf__max_depth'...</td>\n",
       "      <td>0.612802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'clf__criterion': 'gini', 'clf__max_depth': 3...</td>\n",
       "      <td>0.396576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Название модели                                   Параметры модели  \\\n",
       "0      LogisticRegression  {'clf__C': 10, 'clf__fit_intercept': True, 'cl...   \n",
       "1  DecisionTreeClassifier  {'clf__criterion': 'entropy', 'clf__max_depth'...   \n",
       "2  RandomForestClassifier  {'clf__criterion': 'gini', 'clf__max_depth': 3...   \n",
       "\n",
       "   f1_score  \n",
       "0  0.762070  \n",
       "1  0.612802  \n",
       "2  0.396576  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе мы обучили 3 модели и получили следующие результаты:\n",
    "\n",
    "- **Логистическая регрессия** получила результат **f1_score** на тестовой выборке равный 0.762070\n",
    "- **Дерево решений** получило результат **f1_score** на тестовой выборке равный 0.612802\n",
    "- **Случайый лес** получила результат **f1_score** на тестовой выборке равный 0.396576\n",
    "\n",
    "**Логистическая регрессия** показала лучший результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При выполнении работы, мы загрузили и посмотрели на данные. В нашем датасете 159571 строк содержащих комментарии пользователей, из них:\n",
    "- 143346 шт являются **'Позитивными'**, это почти 90% данных\n",
    "- 16225 шт являются **'Негативными'**, это около 10% данных\n",
    "\n",
    "Убедились, что в данных нет пропусков и дубликатов. \n",
    "\n",
    "Далее приступили к обработке данных. На данном этапе мы получили леммы в предложениях и разбили данные на обучающую и тестовую выборку, после этого приступили к обучению моделей.  \n",
    "\n",
    "Мы обучили 3 модели и получили следующие результаты:\n",
    "- **Логистическая регрессия** получила результат **f1_score** на тестовой выборке равный 0.762070\n",
    "- **Дерево решений** получило результат **f1_score** на тестовой выборке равный 0.612802\n",
    "- **Случайый лес** получила результат **f1_score** на тестовой выборке равный 0.396576\n",
    "\n",
    "**Логистическая регрессия** показала лучший результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
